{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3299f416-a173-49f6-87f8-104af07c662b",
   "metadata": {},
   "source": [
    "## Working Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71324f28-bdc5-461f-8999-3fa25148cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "from utils import generate_embeddings, get_portkey_client\n",
    "from pdf_reader import extract_text_from_pdf\n",
    "from vector_store import initialize_vector_store, add_to_vector_store, create_schema\n",
    "\n",
    "pdf_path = \"ask_hp_faq.pdf\"\n",
    "pdf_text = extract_text_from_pdf(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f914c559-c0e5-4fb1-ba3d-45a5316a3217",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f21b9bb6-05d2-4c2e-b319-270cb64291b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cecile.yang/Library/Caches/pypoetry/virtualenvs/oncall-agent-CWRHTJmz-py3.13/lib/python3.13/site-packages/portkey_ai/api_resources/base_client.py:154: PydanticDeprecatedSince20: The `construct` method is deprecated; use `model_construct` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  self.allHeaders = self._build_headers(Options.construct())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'FAQ' has been deleted.\n",
      "_CollectionConfig(name='FAQ', description=None, generative_config=None, inverted_index_config=_InvertedIndexConfig(bm25=_BM25Config(b=0.75, k1=1.2), cleanup_interval_seconds=60, index_null_state=False, index_property_length=False, index_timestamps=False, stopwords=_StopwordsConfig(preset=<StopwordsPreset.EN: 'en'>, additions=None, removals=None)), multi_tenancy_config=_MultiTenancyConfig(enabled=False, auto_tenant_creation=False, auto_tenant_activation=False), properties=[_Property(name='text', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=None, vectorizer='none'), _Property(name='file_path', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=None, vectorizer='none')], references=[], replication_config=_ReplicationConfig(factor=1, async_enabled=False, deletion_strategy=<ReplicationDeletionStrategy.NO_AUTOMATED_RESOLUTION: 'NoAutomatedResolution'>), reranker_config=None, sharding_config=_ShardingConfig(virtual_per_physical=128, desired_count=1, actual_count=1, desired_virtual_count=128, actual_virtual_count=128, key='_id', strategy='hash', function='murmur3'), vector_index_config=_VectorIndexConfigHNSW(quantizer=None, cleanup_interval_seconds=300, distance_metric=<VectorDistances.COSINE: 'cosine'>, dynamic_ef_min=100, dynamic_ef_max=500, dynamic_ef_factor=8, ef=-1, ef_construction=128, filter_strategy=<VectorFilterStrategy.SWEEPING: 'sweeping'>, flat_search_cutoff=40000, max_connections=32, skip=False, vector_cache_max_objects=1000000000000), vector_index_type=<VectorIndexType.HNSW: 'hnsw'>, vectorizer_config=None, vectorizer=<Vectorizers.NONE: 'none'>, vector_config=None)\n",
      "schema created\n"
     ]
    }
   ],
   "source": [
    "def chunk_text(text):\n",
    "    return text.split(\". \")\n",
    "\n",
    "pdf_text_inputs = chunk_text(pdf_text)\n",
    "vector_store_client = initialize_vector_store()\n",
    "\n",
    "# get port key client\n",
    "client = get_portkey_client()\n",
    "\n",
    "# create FAQ schema\n",
    "create_schema(vector_store_client, \"FAQ\")\n",
    "\n",
    "# get a FAQ collection bucket\n",
    "collection = vector_store_client.collections.get(\"FAQ\")\n",
    "\n",
    "for text in pdf_text_inputs:\n",
    "    gen_uuid = uuid.uuid4()\n",
    "    embedding_response = client.embeddings.create(input=text, model=\"text-embedding-3-large\", encoding_format=\"float\").data[0].embedding\n",
    "    collection.data.insert(uuid=gen_uuid.__str__(), properties={\"text\": text}, vector=embedding_response)    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca338ecc-4b19-45c2-8137-a1fa63994162",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I was the discovery-platform oncall and found the `[getCollectionConfig] - error deserializing please check runtime and fix config` log is the top 1 in feed-service. By checking the git commit history, the code was added by Ujjwal a year ago. Can you help check if anything changed recently which caused this log and fix it?\"\n",
    "\n",
    "query_embedding = client.embeddings.create(input=query, model=\"text-embedding-3-large\", encoding_format=\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5907abf-ce45-4946-ab82-dbb2704f55ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_collection = vector_store_client.collections.get(\"FAQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ada47121-e408-4785-a1f1-3d6444d30065",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = new_collection.query.near_vector(near_vector=query_embedding.data[0].embedding, limit=5, filters=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "255bde98-1166-4896-bfee-b38a778b5560",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_context = '\\n\\n'.join([obj.properties['text'] for obj in result.objects])\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Please answer this question: {query}, based on the following context, and give the context that you used in the answer as part of the output.\n",
    "\n",
    "{relevant_context}\n",
    "\"\"\"\n",
    "\n",
    "# print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "526ec106-31f1-4de9-99f8-9d95656ed429",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\", # try a better model\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48184f32-a265-4f93-97f7-d3c16bdd2298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adbb76c-6b3c-4f69-9aa6-297eaf622056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51f3493-9882-403b-862a-3f13deb4e1f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oncall_agent_test",
   "language": "python",
   "name": "oncall-agent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
